<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>cs231n课程作业2-part2：卷积神经网络的模块化实现 | plWang&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="机器学习神经网络深度学习" />
  
  
  
  
  <meta name="description" content="本文主要介绍cs231n课程作业assignment2的第二部分：卷积神经网络中各种层的实现以及如何实现一个完整的卷积神经网络并在Cifar-10训练集上进行测试。">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n课程作业2-Part2：卷积神经网络的模块化实现">
<meta property="og:url" content="https://plWang.github.io/2017/02/09/cs231n-Assignment2-Part2/index.html">
<meta property="og:site_name" content="plWang's Blog">
<meta property="og:description" content="本文主要介绍cs231n课程作业assignment2的第二部分：卷积神经网络中各种层的实现以及如何实现一个完整的卷积神经网络并在Cifar-10训练集上进行测试。">
<meta property="og:updated_time" content="2017-02-09T06:33:14.772Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CS231n课程作业2-Part2：卷积神经网络的模块化实现">
<meta name="twitter:description" content="本文主要介绍cs231n课程作业assignment2的第二部分：卷积神经网络中各种层的实现以及如何实现一个完整的卷积神经网络并在Cifar-10训练集上进行测试。">
  
    <link rel="alternate" href="/atom.xml" title="plWang&#39;s Blog" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  
    <link rel="stylesheet" href="/css/header-post.css" ><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

  

</head>

<body>
  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="border-width: 0;">
                <p>plWang&#39;s Blog</p>
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="nav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-cs231n-Assignment2-Part2" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      CS231n课程作业2-Part2：卷积神经网络的模块化实现
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2017/02/09/cs231n-Assignment2-Part2/" class="article-date">
	  <time datetime="2017-02-09T06:28:00.000Z" itemprop="datePublished">2017-02-09</time>
	</a>

      
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要介绍cs231n课程作业assignment2的第二部分：卷积神经网络中各种层的实现以及如何实现一个完整的卷积神经网络并在Cifar-10训练集上进行测试。</p>
<a id="more"></a>
<h2 id="1-卷积层的实现"><a href="#1-卷积层的实现" class="headerlink" title="1. 卷积层的实现"></a>1. 卷积层的实现</h2><h3 id="1-1-前向传播简单实现"><a href="#1-1-前向传播简单实现" class="headerlink" title="1.1 前向传播简单实现"></a>1.1 前向传播简单实现</h3><p>卷积层前向传播时进行的主要操作就是让滤波器集合与输入图像进行卷积，本质上即是让滤波器在输入数据上进行滑动并进行内积，因此最原始的想法就是使用简单的for循环将滤波器与输入图像的各个位置进行内积。实现的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_forward_naive</span><span class="params">(x, w, b, conv_param)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  A naive implementation of the forward pass for a convolutional layer.</div><div class="line"></div><div class="line">  The input consists of N data points, each with C channels, height H and width</div><div class="line">  W. We convolve each input with F different filters, where each filter spans</div><div class="line">  all C channels and has height HH and width HH.</div><div class="line"></div><div class="line">  Input:</div><div class="line">  - x: Input data of shape (N, C, H, W)</div><div class="line">  - w: Filter weights of shape (F, C, HH, WW)</div><div class="line">  - b: Biases, of shape (F,)</div><div class="line">  - conv_param: A dictionary with the following keys:</div><div class="line">    - 'stride': The number of pixels between adjacent receptive fields in the</div><div class="line">      horizontal and vertical directions.</div><div class="line">    - 'pad': The number of pixels that will be used to zero-pad the input.</div><div class="line"></div><div class="line">  Returns a tuple of:</div><div class="line">  - out: Output data, of shape (N, F, H', W') where H' and W' are given by</div><div class="line">    H' = 1 + (H + 2 * pad - HH) / stride</div><div class="line">    W' = 1 + (W + 2 * pad - WW) / stride</div><div class="line">  - cache: (x, w, b, conv_param)</div><div class="line">  """</div><div class="line">  out = <span class="keyword">None</span></div><div class="line">  </div><div class="line">  pad = conv_param[<span class="string">'pad'</span>]</div><div class="line">  stride = conv_param[<span class="string">'stride'</span>]</div><div class="line">  N, C, H, W = x.shape</div><div class="line">  F, C, HH, WW = w.shape</div><div class="line">  x_pad = np.zeros((N, C, H+<span class="number">2</span>*pad, W+<span class="number">2</span>*pad))</div><div class="line">  <span class="comment"># padding x</span></div><div class="line">  x_pad = np.pad(x, [(<span class="number">0</span>,),(<span class="number">0</span>,),(pad,),(pad,)],<span class="string">'constant'</span>)</div><div class="line">  </div><div class="line">  </div><div class="line">  W_1 = (W - WW + <span class="number">2</span> * pad) / stride + <span class="number">1</span></div><div class="line">  H_1 = (H - HH + <span class="number">2</span> * pad) / stride + <span class="number">1</span></div><div class="line">  out = np.zeros((N, F, H_1, W_1))</div><div class="line">  </div><div class="line">  <span class="comment"># convolution, niave implementation  </span></div><div class="line">  <span class="keyword">for</span> n <span class="keyword">in</span> xrange(N):</div><div class="line">      <span class="keyword">for</span> f <span class="keyword">in</span> xrange(F):</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(H_1):</div><div class="line">            ii = i * stride </div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(W_1):</div><div class="line">                jj = j * stride</div><div class="line">                out[n,f,i,j] = np.sum(x_pad[n,:,ii:ii+HH,jj:jj+WW] * w[f,:,:,:]) + b[f]</div><div class="line">  </div><div class="line">  cache = (x, w, b, conv_param)</div><div class="line">  <span class="keyword">return</span> out, cache</div></pre></td></tr></table></figure>
<h3 id="1-2-反向传播简单实现"><a href="#1-2-反向传播简单实现" class="headerlink" title="1.2 反向传播简单实现"></a>1.2 反向传播简单实现</h3><p>卷积层的梯度（无论对数据还是权重）实际上还是一个卷积，但是是和空间上翻转的滤波器进行卷积。因此实现方法上也可以利用简单的for循环完成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_backward_naive</span><span class="params">(dout, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  A naive implementation of the backward pass for a convolutional layer.</div><div class="line"></div><div class="line">  Inputs:</div><div class="line">  - dout: Upstream derivatives.</div><div class="line">  - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive</div><div class="line"></div><div class="line">  Returns a tuple of:</div><div class="line">  - dx: Gradient with respect to x</div><div class="line">  - dw: Gradient with respect to w</div><div class="line">  - db: Gradient with respect to b</div><div class="line">  """</div><div class="line">  dx, dw, db = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line">  </div><div class="line">  x, w, b, conv_param = cache</div><div class="line">  pad = conv_param[<span class="string">'pad'</span>] </div><div class="line">  stride = conv_param[<span class="string">'stride'</span>]</div><div class="line">  </div><div class="line">  N, F, H_1, W_1 = dout.shape</div><div class="line">  F, C, HH, WW = w.shape</div><div class="line">  N, C, H, W = x.shape</div><div class="line">  </div><div class="line">  dx = np.zeros_like(x)</div><div class="line">  dw = np.zeros_like(w)</div><div class="line">  db = np.zeros_like(b)</div><div class="line">  <span class="comment"># padding</span></div><div class="line">  x_pad = np.pad(x, [(<span class="number">0</span>,), (<span class="number">0</span>,), (pad,), (pad,)], <span class="string">'constant'</span>)</div><div class="line">  dx_pad = np.pad(dx, [(<span class="number">0</span>,), (<span class="number">0</span>,), (pad,), (pad,)], <span class="string">'constant'</span>)</div><div class="line">  <span class="comment"># convolution, naive implementation</span></div><div class="line">  <span class="keyword">for</span> n <span class="keyword">in</span> xrange(N):</div><div class="line">      <span class="keyword">for</span> f <span class="keyword">in</span> xrange(F):</div><div class="line">          <span class="keyword">for</span> i <span class="keyword">in</span> xrange(H_1):</div><div class="line">              ii = i * stride  </div><div class="line">              <span class="keyword">for</span> j <span class="keyword">in</span> xrange(W_1):</div><div class="line">                  jj = j * stride</div><div class="line">                  dx_pad[n, :, ii:ii+HH, jj:jj+WW] += w[f] * dout[n,f,i,j]</div><div class="line">                  dw[f] += x_pad[n,:, ii:ii+HH,jj:jj+WW] * dout[n,f,i,j] </div><div class="line">                  db[f] += dout[n,f,i,j]</div><div class="line">                    </div><div class="line">  dx = dx_pad[:, : , pad:pad+H, pad:pad+W]</div><div class="line">  </div><div class="line">  <span class="keyword">return</span> dx, dw, db</div></pre></td></tr></table></figure>
<h3 id="1-3-前向传播的快速实现"><a href="#1-3-前向传播的快速实现" class="headerlink" title="1.3 前向传播的快速实现"></a>1.3 前向传播的快速实现</h3><p>卷积操作可以通过im2col操作转化成矩阵乘法的形式，这种方法的有点是矩阵乘法有很多成熟的快速实现方式，但是它也有一个很大的缺点就是占用内存过多，因为im2col操作转化成矩阵后输入数据的很多数字在矩阵中都重复出现了。</p>
<h3 id="1-4-反向传播的快速实现"><a href="#1-4-反向传播的快速实现" class="headerlink" title="1.4 反向传播的快速实现"></a>1.4 反向传播的快速实现</h3><p>与前向传播类似，反向传播由于也是卷积的形式，因此也可以通过im2col操作将卷积转化为矩阵乘法的形式。</p>
<h2 id="2-Pooling层的实现"><a href="#2-Pooling层的实现" class="headerlink" title="2.Pooling层的实现"></a>2.Pooling层的实现</h2><p>与卷积层类似，Pooling层中所做的操作也是将滤波器在输入数据上滑动，只不过内积操作改为求最大值。因此实现方法也与卷积层的实现方法类似。</p>
<h3 id="2-1-前向传播"><a href="#2-1-前向传播" class="headerlink" title="2.1 前向传播"></a>2.1 前向传播</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_forward_naive</span><span class="params">(x, pool_param)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  A naive implementation of the forward pass for a max pooling layer.</div><div class="line"></div><div class="line">  Inputs:</div><div class="line">  - x: Input data, of shape (N, C, H, W)</div><div class="line">  - pool_param: dictionary with the following keys:</div><div class="line">    - 'pool_height': The height of each pooling region</div><div class="line">    - 'pool_width': The width of each pooling region</div><div class="line">    - 'stride': The distance between adjacent pooling regions</div><div class="line"></div><div class="line">  Returns a tuple of:</div><div class="line">  - out: Output data</div><div class="line">  - cache: (x, pool_param)</div><div class="line">  """</div><div class="line">  out = <span class="keyword">None</span></div><div class="line">  </div><div class="line">  N, C, H, W = x.shape</div><div class="line">  pool_height = pool_param[<span class="string">'pool_height'</span>]</div><div class="line">  pool_width = pool_param[<span class="string">'pool_width'</span>]</div><div class="line">  stride = pool_param[<span class="string">'stride'</span>]</div><div class="line">  </div><div class="line">  H1 = (H - pool_height) / stride + <span class="number">1</span></div><div class="line">  W1 = (W - pool_width) / stride + <span class="number">1</span></div><div class="line">  out = np.zeros((N,C,H1,W1))</div><div class="line">  <span class="keyword">for</span> n <span class="keyword">in</span> xrange(N):</div><div class="line">      <span class="keyword">for</span> c <span class="keyword">in</span> xrange(C):</div><div class="line">          <span class="keyword">for</span> i <span class="keyword">in</span> xrange(H1):</div><div class="line">              ii = i * stride</div><div class="line">              <span class="keyword">for</span> j <span class="keyword">in</span> xrange(W1):</div><div class="line">                  jj = j * stride</div><div class="line">                  out[n,c,i,j] =        				   np.max(x[n,c,ii:ii+pool_height,jj:jj+pool_width])</div><div class="line">                    </div><div class="line">  cache = (x, pool_param)</div><div class="line">  <span class="keyword">return</span> out, cache</div></pre></td></tr></table></figure>
<h3 id="2-2-反向传播"><a href="#2-2-反向传播" class="headerlink" title="2.2 反向传播"></a>2.2 反向传播</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_backward_naive</span><span class="params">(dout, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  A naive implementation of the backward pass for a max pooling layer.</div><div class="line"></div><div class="line">  Inputs:</div><div class="line">  - dout: Upstream derivatives</div><div class="line">  - cache: A tuple of (x, pool_param) as in the forward pass.</div><div class="line"></div><div class="line">  Returns:</div><div class="line">  - dx: Gradient with respect to x</div><div class="line">  """</div><div class="line">  dx = <span class="keyword">None</span></div><div class="line"></div><div class="line">  x, pool_param = cache</div><div class="line">  pool_height = pool_param[<span class="string">'pool_height'</span>]</div><div class="line">  pool_width = pool_param[<span class="string">'pool_width'</span>]</div><div class="line">  stride = pool_param[<span class="string">'stride'</span>]</div><div class="line">  N, C, H, W = x.shape</div><div class="line">  N, C, H1, W1 = dout.shape</div><div class="line">  dx = np.zeros_like(x)</div><div class="line">  </div><div class="line">  <span class="keyword">for</span> n <span class="keyword">in</span> xrange(N):</div><div class="line">      <span class="keyword">for</span> c <span class="keyword">in</span> xrange(C):</div><div class="line">          <span class="keyword">for</span> i <span class="keyword">in</span> xrange(H1):</div><div class="line">              ii = i * stride</div><div class="line">              <span class="keyword">for</span> j <span class="keyword">in</span> xrange(W1):</div><div class="line">                  jj = j * stride  </div><div class="line">                  window = x[n,c,ii:ii+pool_height,jj:jj+pool_width]</div><div class="line">                  dx[n,c,ii:ii+pool_height,jj:jj+pool_width] = (window==np.max(window)) * dout[n,c,i,j]</div><div class="line">  </div><div class="line">  <span class="keyword">return</span> dx</div></pre></td></tr></table></figure>
<h2 id="3-实现一个三层的CNN-网络"><a href="#3-实现一个三层的CNN-网络" class="headerlink" title="3. 实现一个三层的CNN 网络"></a>3. 实现一个三层的CNN 网络</h2><p>按照上面的方法我们已经实现了CNN网络所需的三种结构的层，接下来把他们组合到一起就可以实现一个CNN网络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="keyword">from</span> cs231n.layers <span class="keyword">import</span> *</div><div class="line"><span class="keyword">from</span> cs231n.fast_layers <span class="keyword">import</span> *</div><div class="line"><span class="keyword">from</span> cs231n.layer_utils <span class="keyword">import</span> *</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreeLayerConvNet</span><span class="params">(object)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  A three-layer convolutional network with the following architecture:</div><div class="line">  </div><div class="line">  conv - relu - 2x2 max pool - affine - relu - affine - softmax</div><div class="line">  </div><div class="line">  The network operates on minibatches of data that have shape (N, C, H, W)</div><div class="line">  consisting of N images, each with height H and width W and with C input</div><div class="line">  channels.</div><div class="line">  """</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim=<span class="params">(<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span>, num_filters=<span class="number">32</span>, filter_size=<span class="number">7</span>,</span></span></div><div class="line">               hidden_dim=<span class="number">100</span>, num_classes=<span class="number">10</span>, weight_scale=<span class="number">1e-3</span>, reg=<span class="number">0.0</span>,</div><div class="line">               dtype=np.float32):</div><div class="line">    <span class="string">"""</span></div><div class="line">    Initialize a new network.</div><div class="line">    </div><div class="line">    Inputs:</div><div class="line">    - input_dim: Tuple (C, H, W) giving size of input data</div><div class="line">    - num_filters: Number of filters to use in the convolutional layer</div><div class="line">    - filter_size: Size of filters to use in the convolutional layer</div><div class="line">    - hidden_dim: Number of units to use in the fully-connected hidden layer</div><div class="line">    - num_classes: Number of scores to produce from the final affine layer.</div><div class="line">    - weight_scale: Scalar giving standard deviation for random initialization</div><div class="line">      of weights.</div><div class="line">    - reg: Scalar giving L2 regularization strength</div><div class="line">    - dtype: numpy datatype to use for computation.</div><div class="line">    """</div><div class="line">    self.params = &#123;&#125;</div><div class="line">    self.reg = reg</div><div class="line">    self.dtype = dtype</div><div class="line">    </div><div class="line">    C,H,W = input_dim</div><div class="line">    </div><div class="line">    self.params[<span class="string">'W1'</span>] = weight_scale * np.random.randn(num_filters, C, filter_size, filter_size)</div><div class="line">    self.params[<span class="string">'W2'</span>] = weight_scale * np.random.randn((H/<span class="number">2</span>)*(W/<span class="number">2</span>)*num_filters, hidden_dim)</div><div class="line">    self.params[<span class="string">'W3'</span>] = weight_scale * np.random.randn(hidden_dim, num_classes)</div><div class="line">    self.params[<span class="string">'b1'</span>] = np.zeros((num_filters))</div><div class="line">    self.params[<span class="string">'b2'</span>] = np.zeros((hidden_dim))</div><div class="line">    self.params[<span class="string">'b3'</span>] = np.zeros((num_classes))</div><div class="line"></div><div class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> self.params.iteritems():</div><div class="line">      self.params[k] = v.astype(dtype)</div><div class="line">     </div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(self, X, y=None)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Evaluate loss and gradient for the three-layer convolutional network.</div><div class="line">    </div><div class="line">    Input / output: Same API as TwoLayerNet in fc_net.py.</div><div class="line">    """</div><div class="line">    W1, b1 = self.params[<span class="string">'W1'</span>], self.params[<span class="string">'b1'</span>]</div><div class="line">    W2, b2 = self.params[<span class="string">'W2'</span>], self.params[<span class="string">'b2'</span>]</div><div class="line">    W3, b3 = self.params[<span class="string">'W3'</span>], self.params[<span class="string">'b3'</span>]</div><div class="line">    </div><div class="line">    <span class="comment"># pass conv_param to the forward pass for the convolutional layer</span></div><div class="line">    filter_size = W1.shape[<span class="number">2</span>]</div><div class="line">    conv_param = &#123;<span class="string">'stride'</span>: <span class="number">1</span>, <span class="string">'pad'</span>: (filter_size - <span class="number">1</span>) / <span class="number">2</span>&#125;</div><div class="line"></div><div class="line">    <span class="comment"># pass pool_param to the forward pass for the max-pooling layer</span></div><div class="line">    pool_param = &#123;<span class="string">'pool_height'</span>: <span class="number">2</span>, <span class="string">'pool_width'</span>: <span class="number">2</span>, <span class="string">'stride'</span>: <span class="number">2</span>&#125;</div><div class="line"></div><div class="line">    scores = <span class="keyword">None</span></div><div class="line">  </div><div class="line">    out_forward_1, cache_forward_1 = conv_relu_pool_forward(X, self.params[<span class="string">'W1'</span>], self.params[<span class="string">'b1'</span>], conv_param, pool_param)</div><div class="line">    out_forward_2, cache_forward_2 = affine_forward(out_forward_1, self.params[<span class="string">'W2'</span>], self.params[<span class="string">'b2'</span>])</div><div class="line">    out_relu_2, cache_relu_2 = relu_forward(out_forward_2)</div><div class="line">    scores, cache_forward_3 = affine_forward(out_relu_2, self.params[<span class="string">'W3'</span>], self.params[<span class="string">'b3'</span>])</div><div class="line">    </div><div class="line">    <span class="keyword">if</span> y <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">      <span class="keyword">return</span> scores</div><div class="line">    </div><div class="line">    loss, grads = <span class="number">0</span>, &#123;&#125;</div><div class="line">    </div><div class="line">    loss, dout = softmax_loss(scores, y)</div><div class="line">    </div><div class="line">    <span class="comment"># Add regularization</span></div><div class="line">    loss += self.reg * <span class="number">0.5</span> * (np.sum(self.params[<span class="string">'W1'</span>]**<span class="number">2</span>) + np.sum(self.params[<span class="string">'W2'</span>]**<span class="number">2</span>) + np.sum(self.params[<span class="string">'W1'</span>]**<span class="number">2</span>))</div><div class="line"></div><div class="line">    dX3, grads[<span class="string">'W3'</span>], grads[<span class="string">'b3'</span>] = affine_backward(dout, cache_forward_3)</div><div class="line">    dX2 = relu_backward(dX3, cache_relu_2)</div><div class="line">    dX2, grads[<span class="string">'W2'</span>], grads[<span class="string">'b2'</span>] = affine_backward(dX2, cache_forward_2)</div><div class="line">    dX1, grads[<span class="string">'W1'</span>], grads[<span class="string">'b1'</span>] = conv_relu_pool_backward(dX2, cache_forward_1)</div><div class="line"></div><div class="line">    grads[<span class="string">'W3'</span>] += self.reg * self.params[<span class="string">'W3'</span>]</div><div class="line">    grads[<span class="string">'W2'</span>] += self.reg * self.params[<span class="string">'W2'</span>]</div><div class="line">    grads[<span class="string">'W1'</span>] += self.reg * self.params[<span class="string">'W1'</span>]</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> loss, grads</div></pre></td></tr></table></figure>
<p>ThreeLayerConvNet类中包含两个函数方法。__init__函数进行网络中接收网络层数，滤波器尺寸、步长、零填充等超参数并进行网络的初始化。loss函数计算前向传播时得到的分类分数和损失函数等，还有反向传播时的每层的梯度。</p>

      
    </div>
    <footer class="article-footer">
      
        
	<section id="comments" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'plwang';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>



      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/03/10/CS231n assignment3-part1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          CS231n Assignment2-Part1：Image Captioning using vanilla RNN and LSTM
        
      </div>
    </a>
  
  
    <a href="/2017/02/07/CNN_overview/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">卷积神经网络（CNN）概述</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-卷积层的实现"><span class="toc-number">1.</span> <span class="toc-text">1. 卷积层的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-前向传播简单实现"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 前向传播简单实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-反向传播简单实现"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 反向传播简单实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-前向传播的快速实现"><span class="toc-number">1.3.</span> <span class="toc-text">1.3 前向传播的快速实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-反向传播的快速实现"><span class="toc-number">1.4.</span> <span class="toc-text">1.4 反向传播的快速实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Pooling层的实现"><span class="toc-number">2.</span> <span class="toc-text">2.Pooling层的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-前向传播"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 前向传播</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-反向传播"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 反向传播</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-实现一个三层的CNN-网络"><span class="toc-number">3.</span> <span class="toc-text">3. 实现一个三层的CNN 网络</span></a></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      <div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2013 - 2017 plWang&#39;s Blog All Rights Reserved.</p>
	      <p id="copyRightCn">Wang Penglin hold copyright</p>
	</div>
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    
<div style="display: none;">
  <script src="https://s11.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
</div>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/bootstrap.js"></script>




  <script src="/js/dialog.js"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-90550327-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            plWang&#39;s Blog
          </div>
          <div class="panel-body">
            Copyright © 2017 Wang Penglin All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  

</body>
</html>